# ðŸš— AI ê¸°ë°˜ ê³ ê° ë§žì¶¤í˜• ìžë™ì°¨ ì¶”ì²œ ë° ì˜ì—…ì „ëžµ ìžë™í™” ì‹œìŠ¤í…œ

í˜„ëŒ€Â·ê¸°ì•„ì°¨ ì‹¤ì œ íŒë§¤ ë°ì´í„°ë¥¼ í™œìš©í•œ ê³ ê° ì„¸ë¶„í™”, ì°¨ëŸ‰ ì¶”ì²œ, íŒë§¤ ì˜ˆì¸¡, ë¦¬í¬íŠ¸ ìžë™í™”ê¹Œì§€ ì „ ê³¼ì •ì„ ë‹¤ë£¨ëŠ” ì‹¤ì „í˜• ë°ì´í„° ë¶„ì„/AI í”„ë¡œì íŠ¸ìž…ë‹ˆë‹¤.

---

## ðŸ“ ë°ì´í„° êµ¬ì„±

- **ë‚´ë¶€ íŒë§¤ ì‹¤ì  ë°ì´í„°**  
  - í˜„ëŒ€/ê¸°ì•„ì°¨ ì°¨ì¢…ë³„ Â· êµ­ê°€ë³„ Â· ì›”ë³„ Â· ë‚´ìˆ˜/ìˆ˜ì¶œ/ê³µìž¥ ë°ì´í„°

- **ê°€ìƒ ê³ ê° ë°ì´í„°**  
  - ChatGPT ê¸°ë°˜ êµ­ê°€ë³„ ê³ ê° í”„ë¡œí•„ (ì´ë¦„, ì„ í˜¸, êµ¬ë§¤ ì´ë ¥ ë“±)

- **ì™¸ë¶€ ë³´ì¡° ë°ì´í„°**  
  - êµ­ê°€ë³„ GDP, ê¸°í›„ëŒ€, ê²½ìŸì‚¬ íŒë§¤ëŸ‰ ë“±

---

## ðŸ”„ ë°ì´í„° ì „ì²˜ë¦¬

- ë¬¸ìžì—´ ìˆ«ìž ë³€í™˜ (`"5,388"` â†’ `5388`)
- ì»¬ëŸ¼ëª… í†µì¼ ë° í•œê¸€í™” (`'Domestic'` â†’ `'ë‚´ìˆ˜ìš©'`)
- ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (`NaN` â†’ `0`)
- ìˆ˜ì¹˜í˜•/ë²”ì£¼í˜• êµ¬ë¶„ í›„ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì ìš©

```python
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer

categorical_features = ['ì„±ë³„', 'ì°¨ëŸ‰êµ¬ë¶„', 'ê±°ëž˜ë°©ì‹', 'ì œí’ˆì¶œì‹œë…„ì›”', 'ì œí’ˆêµ¬ë§¤ë‚ ì§œ', 'ì¹œí™˜ê²½ì°¨']
numeric_features = ['ì—°ë ¹', 'ê±°ëž˜ê¸ˆì•¡', 'êµ¬ë§¤ë¹ˆë„', 'ê³ ê°ì„¸ê·¸ë¨¼íŠ¸']

preprocessor = ColumnTransformer([
    ('cat', OneHotEncoder(), categorical_features),
    ('num', StandardScaler(), numeric_features)
])
ðŸ‘¥ ê³ ê° ë¶„ì„ ë° ì¶”ì²œ
(1) RFM ê¸°ë°˜ ê³ ê° í´ëŸ¬ìŠ¤í„°ë§
KMeans (K=4): VIP, ì¼ë°˜, ì‹ ê·œ, ì´íƒˆ ê°€ëŠ¥ ê³ ê°

ìž…ë ¥: ê±°ëž˜ì¼, ê¸ˆì•¡, ë¹ˆë„ ë“±

(2) ì¶”ê°€ ê³ ê° ìœ í˜• í´ëŸ¬ìŠ¤í„°ë§
ì„±ë³„, ì°¨ëŸ‰ìœ í˜•, ì¹œí™˜ê²½ ì—¬ë¶€, ì—°ë ¹ ë“± í¬í•¨

Elbow method â†’ ìµœì  K ë„ì¶œ

(3) ì‹ ê·œ ê³ ê° ë¶„ë¥˜ ëª¨ë¸
ëª¨ë¸: GradientBoosting, RandomForest

ì •í™•ë„: í˜„ëŒ€ 99.2%, ê¸°ì•„ 100%

ðŸ“ˆ íŒë§¤/ìˆ˜ì¶œ ì˜ˆì¸¡
Prophet ì‹œê³„ì—´ ëª¨ë¸
python
ë³µì‚¬
íŽ¸ì§‘
from prophet import Prophet

model = Prophet()
model.fit(df_long[['ds', 'y']])
forecast = model.predict(model.make_future_dataframe(periods=12, freq='M'))
ì›”ë³„ ì‹¤ì  ì˜ˆì¸¡ (long format í•„ìš”)

ê³„ì ˆì„±, ì¶”ì„¸ ë°˜ì˜ ê°€ëŠ¥

LightGBM ë‹¤ë³€ëŸ‰ ëª¨ë¸
python
ë³µì‚¬
íŽ¸ì§‘
import lightgbm as lgb

params = {'objective': 'regression', 'metric': 'rmse'}
train_data = lgb.Dataset(X, label=y)
model = lgb.train(params, train_data, num_boost_round=100)
ìž…ë ¥: GDP, êµ­ê°€, ê¸°í›„ëŒ€, ì´ì „ ì‹¤ì  ë“±

íƒ€ê²Ÿ: ë‹¤ìŒë‹¬ ìˆ˜ì¶œëŸ‰ ì˜ˆì¸¡

ðŸ“Š ì‹œê°í™” & ìžë™í™”
Streamlit ëŒ€ì‹œë³´ë“œ: ë¸Œëžœë“œ/êµ­ê°€/ê³ ê°ìœ í˜• ê¸°ë°˜ ì‹œê°í™” ë° ì¶”ì²œ ê²°ê³¼ ì œê³µ

ìžë™í™” ê¸°ëŠ¥:

ë³´ê³ ì„œ ìƒì„±

ê³ ê°ë³„ ì¶”ì²œ ì°¨ëŸ‰ ìžë™ ë°œì†¡

ì „ëžµ ìš”ì•½ ê³µìœ 

ðŸ” ì „ì²´ íŒŒì´í”„ë¼ì¸ (ìš”ì•½)
mermaid
ë³µì‚¬
íŽ¸ì§‘
graph TD
A[ë°ì´í„° ìˆ˜ì§‘] --> B[ì „ì²˜ë¦¬]
B --> C1[RFM í´ëŸ¬ìŠ¤í„°ë§]
C1 --> C2[ê³ ê° ìœ í˜• í´ëŸ¬ìŠ¤í„°ë§]
C2 --> D[ì‹ ê·œ ê³ ê° ì˜ˆì¸¡]
D --> E[ì°¨ëŸ‰ ì¶”ì²œ/ì „ëžµ ì œì•ˆ]
B --> F1[Prophet ì˜ˆì¸¡]
B --> F2[LightGBM ì˜ˆì¸¡]
F1 --> G[ëŒ€ì‹œë³´ë“œ ì‹œê°í™”]
F2 --> G
E --> G
